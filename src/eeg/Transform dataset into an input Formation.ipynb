{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Preprocessing Methods\n",
    "from preprocessModule import *\n",
    "\n",
    "# Transform preprocessed signal into an input formation\n",
    "from transformModule import *\n",
    "\n",
    "# Plot methods for various input data\n",
    "from plotModule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DEAP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEAP Dataset Description\n",
    "* __32 participants__\n",
    "* __40 clips__ for each participant\n",
    "* Evaluation : __Valence, Arousal, Dominance, Like__ (1 to 9)\n",
    "\n",
    "### Setting & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEAP_channels = {\"FP1\":0, \"AF3\":1, \"F3\":2, \"F7\":3,\n",
    "                 \"FC5\":4, \"FC1\":5, \"C3\":6, \"T7\":7,\n",
    "                 \"CP5\":8, \"CP1\":9, \"P3\":10,\n",
    "                 \"P7\":11, \"PO3\":12, \"O1\":13, \n",
    "                 \"OZ\":14, \"PZ\":15, \"FP2\":16, \n",
    "                 \"AF4\":17, \"FZ\":18, \"F4\":19,\n",
    "                 \"F8\":20, \"FC6\":21, \"FC2\":22,\n",
    "                 \"CZ\":23, \"C4\":24, \"T8\":25,\n",
    "                 \"CP6\":26, \"CP2\":27, \"P4\":28,\n",
    "                 \"P8\":29, \"PO4\":30, \"O2\":31}\n",
    "\n",
    "DEAP_all_channel_names = list(DEAP_channels.keys())\n",
    "DEAP_all_channel_values = list(DEAP_channels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization ============================\n",
    "# Label list\n",
    "label_list = [] # list of tuple (V,A,D,L)\n",
    "\n",
    "# Input list \n",
    "fftMap_list = [] # Fast Fourier Transform Map\n",
    "base_fftMap_list = [] # base(3sec) fft map list\n",
    "\n",
    "fd_list = [] # FD pattern\n",
    "base_fd_list = [] \n",
    "# ===========================================\n",
    "\n",
    "# Parameters ===============================\n",
    "freqs = [freq for freq in range(4,46,1)]\n",
    "chosen_channels = DEAP_all_channel_values\n",
    "# openBCI default channels\n",
    "#chosen_channels = [0, 16, 6, 24, 11, 20, 13, 31] # [\"FP1\", \"FP2\", \"C3\", \"C4\", \"P7\", \"P8\", \"O1\", \"O2\"]\n",
    "\n",
    "sf = 128 \n",
    "chunk_size = 10 * sf\n",
    "overlap = 5 * sf\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traverse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 분석 끝\n",
      "Mon Apr 13 02:51:22 2020\n",
      "2 분석 끝\n",
      "Mon Apr 13 02:51:29 2020\n",
      "3 분석 끝\n",
      "Mon Apr 13 02:51:37 2020\n",
      "4 분석 끝\n",
      "Mon Apr 13 02:51:43 2020\n",
      "5 분석 끝\n",
      "Mon Apr 13 02:51:50 2020\n",
      "6 분석 끝\n",
      "Mon Apr 13 02:51:57 2020\n",
      "7 분석 끝\n",
      "Mon Apr 13 02:52:03 2020\n",
      "8 분석 끝\n",
      "Mon Apr 13 02:52:10 2020\n",
      "9 분석 끝\n",
      "Mon Apr 13 02:52:18 2020\n",
      "10 분석 끝\n",
      "Mon Apr 13 02:52:27 2020\n",
      "11 분석 끝\n",
      "Mon Apr 13 02:52:35 2020\n",
      "12 분석 끝\n",
      "Mon Apr 13 02:52:42 2020\n",
      "13 분석 끝\n",
      "Mon Apr 13 02:52:50 2020\n",
      "14 분석 끝\n",
      "Mon Apr 13 02:52:58 2020\n",
      "15 분석 끝\n",
      "Mon Apr 13 02:53:05 2020\n",
      "16 분석 끝\n",
      "Mon Apr 13 02:53:13 2020\n",
      "17 분석 끝\n",
      "Mon Apr 13 02:53:21 2020\n",
      "18 분석 끝\n",
      "Mon Apr 13 02:53:28 2020\n",
      "19 분석 끝\n",
      "Mon Apr 13 02:53:35 2020\n",
      "20 분석 끝\n",
      "Mon Apr 13 02:53:42 2020\n",
      "21 분석 끝\n",
      "Mon Apr 13 02:53:49 2020\n",
      "22 분석 끝\n",
      "Mon Apr 13 02:53:57 2020\n",
      "23 분석 끝\n",
      "Mon Apr 13 02:54:04 2020\n",
      "24 분석 끝\n",
      "Mon Apr 13 02:54:11 2020\n",
      "25 분석 끝\n",
      "Mon Apr 13 02:54:19 2020\n",
      "26 분석 끝\n",
      "Mon Apr 13 02:54:26 2020\n",
      "27 분석 끝\n",
      "Mon Apr 13 02:54:33 2020\n",
      "28 분석 끝\n",
      "Mon Apr 13 02:54:40 2020\n",
      "29 분석 끝\n",
      "Mon Apr 13 02:54:48 2020\n",
      "30 분석 끝\n",
      "Mon Apr 13 02:54:56 2020\n",
      "31 분석 끝\n",
      "Mon Apr 13 02:55:03 2020\n",
      "32 분석 끝\n",
      "Mon Apr 13 02:55:10 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "eeg_path = \"EEG dataset/DEAP/physiological_recordings/data_preprocessed_python/data_preprocessed_python/\"\n",
    "\n",
    "# [ Loop 1 ] 32 Participants\n",
    "for participant_id in range(1, 33):\n",
    "    file_name = \"s\" + str(int(participant_id/10)) + str(participant_id%10) + \".dat\"\n",
    "    s = pickle.load(open(eeg_path + file_name, 'rb'), encoding='latin1')\n",
    "    \n",
    "    labels = s['labels']\n",
    "    data = s['data']\n",
    "    \n",
    "    # [ Loop 2 ] 40 Trials\n",
    "    for trial_id in range(0, 40):      \n",
    "        # label \n",
    "        V, A, D, L = labels[trial_id]\n",
    "        \n",
    "        base_signal = data[trial_id][:, :sf * 3] # 3sec\n",
    "        total_signal = data[trial_id][:, sf * 3:] # 60sec\n",
    "        \n",
    "        # all_chunks = [[start//sf, (start+chunk_size)//sf] for start in range(0, sf*60-chunk_size+1, chunk_size-overlap)]\n",
    "        # print(\"Total %d chunks\",%(len(all_chunks))); print(all_chunks)\n",
    "        \n",
    "        all_chunks = [total_signal[:, start:start+chunk_size] \n",
    "                     for start in range(0, sf*60-chunk_size+1, chunk_size-overlap)]\n",
    "        \n",
    "        # processing base signal==================================\n",
    "        base_fftMap = computefftMap(base_signal, chosen_channels, freqs, sf)\n",
    "        base_fftMap_list.append(base_fftMap)\n",
    "        base_fd = computeFD(base_signal, chosen_channels)\n",
    "        base_fd_list.append(base_fd)\n",
    "        # ========================================================\n",
    "        \n",
    "        # [ Loop 3 ] Sliding window\n",
    "        for chunk in all_chunks:\n",
    "            # fftMap (2d array) ======================\n",
    "            fftMap = computefftMap(chunk, chosen_channels, freqs, sf)    \n",
    "            fftMap_list.append(fftMap)\n",
    "            # ========================================\n",
    "            # FD pattern (1d array)====================\n",
    "            fd = computeFD(chunk, chosen_channels)\n",
    "            fd_list.append(fd)\n",
    "            # =========================================\n",
    "            label_list.append((V,A,D,L))\n",
    "    print(\"Participant %d Ended\"%(participant_id))\n",
    "    print(time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noc = len(fftMap_list) // 1280 # num of chunks\n",
    "len(label_list) == len(fftMap_list) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_index(p_id, t_id, c_id, noc):\n",
    "    return (noc * 40) * p_id + noc * t_id + c_id\n",
    "\n",
    "def get_base_index(p_id, t_id):\n",
    "    return 40 * p_id + t_id\n",
    "\n",
    "# get p_id, t_id, c_id\n",
    "def from_data_index(index, noc):\n",
    "    # return index//40, index%40\n",
    "    p_id,remain = index // (noc*40), index % (noc*40)\n",
    "    return p_id, remain//noc, remain%noc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "save_option = \"origin\" # \"diff\"\n",
    "\n",
    "for i in range(len(fftMap_list)):\n",
    "    # activated signals (60sec)\n",
    "    if save_option == \"origin\":\n",
    "        data_list.append([fftMap_list[i], label_list[i]]) # **\n",
    "        \n",
    "    # 60sec(activate) - 3sec(base)\n",
    "    elif save_option == \"diff\":\n",
    "        p_id, t_id, c_id = from_data_index(i)\n",
    "        base_index = get_base_index(p_id, t_id)\n",
    "        \n",
    "        diff = np.array(scale(fd_list[i])) - np.array(scale(base_fd_list[base_index]))\n",
    "        data_list.append([diff, label_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DEAP_fftMap_10sec_5over.pickle', 'wb') as f:\n",
    "    pickle.dump(data_list, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
