{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Preprocessing Methods\n",
    "from preprocessModule import *\n",
    "\n",
    "# Transform preprocessed signal into an input formation\n",
    "from transformModule import *\n",
    "\n",
    "# Plot methods for various input data\n",
    "from plotModule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DEAP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEAP Dataset Description\n",
    "* __32 participants__\n",
    "* __40 clips__ for each participant\n",
    "* Evaluation : __Valence, Arousal, Dominance, Like__ (1 to 9)\n",
    "\n",
    "### Setting & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEAP_channels = {\"FP1\":0, \"AF3\":1, \"F3\":2, \"F7\":3,\n",
    "                 \"FC5\":4, \"FC1\":5, \"C3\":6, \"T7\":7,\n",
    "                 \"CP5\":8, \"CP1\":9, \"P3\":10,\n",
    "                 \"P7\":11, \"PO3\":12, \"O1\":13, \n",
    "                 \"OZ\":14, \"PZ\":15, \"FP2\":16, \n",
    "                 \"AF4\":17, \"FZ\":18, \"F4\":19,\n",
    "                 \"F8\":20, \"FC6\":21, \"FC2\":22,\n",
    "                 \"CZ\":23, \"C4\":24, \"T8\":25,\n",
    "                 \"CP6\":26, \"CP2\":27, \"P4\":28,\n",
    "                 \"P8\":29, \"PO4\":30, \"O2\":31}\n",
    "\n",
    "DEAP_all_channel_names = list(DEAP_channels.keys())\n",
    "DEAP_all_channel_values = list(DEAP_channels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization ============================\n",
    "# Label list\n",
    "label_list = [] # list of tuple (V,A,D,L)\n",
    "\n",
    "# Input list \n",
    "fftMap_list = [] # Fast Fourier Transform Map\n",
    "base_fftMap_list = [] # base(3sec) fft map list\n",
    "\n",
    "fd_list = [] # FD pattern\n",
    "base_fd_list = [] \n",
    "# ===========================================\n",
    "\n",
    "# Parameters ===============================\n",
    "freqs = [freq for freq in range(4,46,1)]\n",
    "chosen_channels = DEAP_all_channel_values\n",
    "# openBCI default channels\n",
    "#chosen_channels = [0, 16, 6, 24, 11, 20, 13, 31] # [\"FP1\", \"FP2\", \"C3\", \"C4\", \"P7\", \"P8\", \"O1\", \"O2\"]\n",
    "\n",
    "sf = 128 \n",
    "chunk_size = 10 * sf\n",
    "overlap = 5 * sf\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traverse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 분석 끝\n",
      "Mon Apr 13 02:51:22 2020\n",
      "2 분석 끝\n",
      "Mon Apr 13 02:51:29 2020\n",
      "3 분석 끝\n",
      "Mon Apr 13 02:51:37 2020\n",
      "4 분석 끝\n",
      "Mon Apr 13 02:51:43 2020\n",
      "5 분석 끝\n",
      "Mon Apr 13 02:51:50 2020\n",
      "6 분석 끝\n",
      "Mon Apr 13 02:51:57 2020\n",
      "7 분석 끝\n",
      "Mon Apr 13 02:52:03 2020\n",
      "8 분석 끝\n",
      "Mon Apr 13 02:52:10 2020\n",
      "9 분석 끝\n",
      "Mon Apr 13 02:52:18 2020\n",
      "10 분석 끝\n",
      "Mon Apr 13 02:52:27 2020\n",
      "11 분석 끝\n",
      "Mon Apr 13 02:52:35 2020\n",
      "12 분석 끝\n",
      "Mon Apr 13 02:52:42 2020\n",
      "13 분석 끝\n",
      "Mon Apr 13 02:52:50 2020\n",
      "14 분석 끝\n",
      "Mon Apr 13 02:52:58 2020\n",
      "15 분석 끝\n",
      "Mon Apr 13 02:53:05 2020\n",
      "16 분석 끝\n",
      "Mon Apr 13 02:53:13 2020\n",
      "17 분석 끝\n",
      "Mon Apr 13 02:53:21 2020\n",
      "18 분석 끝\n",
      "Mon Apr 13 02:53:28 2020\n",
      "19 분석 끝\n",
      "Mon Apr 13 02:53:35 2020\n",
      "20 분석 끝\n",
      "Mon Apr 13 02:53:42 2020\n",
      "21 분석 끝\n",
      "Mon Apr 13 02:53:49 2020\n",
      "22 분석 끝\n",
      "Mon Apr 13 02:53:57 2020\n",
      "23 분석 끝\n",
      "Mon Apr 13 02:54:04 2020\n",
      "24 분석 끝\n",
      "Mon Apr 13 02:54:11 2020\n",
      "25 분석 끝\n",
      "Mon Apr 13 02:54:19 2020\n",
      "26 분석 끝\n",
      "Mon Apr 13 02:54:26 2020\n",
      "27 분석 끝\n",
      "Mon Apr 13 02:54:33 2020\n",
      "28 분석 끝\n",
      "Mon Apr 13 02:54:40 2020\n",
      "29 분석 끝\n",
      "Mon Apr 13 02:54:48 2020\n",
      "30 분석 끝\n",
      "Mon Apr 13 02:54:56 2020\n",
      "31 분석 끝\n",
      "Mon Apr 13 02:55:03 2020\n",
      "32 분석 끝\n",
      "Mon Apr 13 02:55:10 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "eeg_path = \"EEG dataset/DEAP/physiological_recordings/data_preprocessed_python/data_preprocessed_python/\"\n",
    "\n",
    "# [ Loop 1 ] 32 Participants\n",
    "for participant_id in range(1, 33):\n",
    "    file_name = \"s\" + str(int(participant_id/10)) + str(participant_id%10) + \".dat\"\n",
    "    s = pickle.load(open(eeg_path + file_name, 'rb'), encoding='latin1')\n",
    "    \n",
    "    labels = s['labels']\n",
    "    data = s['data']\n",
    "    \n",
    "    # [ Loop 2 ] 40 Trials\n",
    "    for trial_id in range(0, 40):      \n",
    "        # label \n",
    "        V, A, D, L = labels[trial_id]\n",
    "        \n",
    "        base_signal = data[trial_id][:, :sf * 3] # 3sec\n",
    "        total_signal = data[trial_id][:, sf * 3:] # 60sec\n",
    "        \n",
    "        # all_chunks = [[start//sf, (start+chunk_size)//sf] for start in range(0, sf*60-chunk_size+1, chunk_size-overlap)]\n",
    "        # print(\"Total %d chunks\",%(len(all_chunks))); print(all_chunks)\n",
    "        \n",
    "        all_chunks = [total_signal[:, start:start+chunk_size] \n",
    "                     for start in range(0, sf*60-chunk_size+1, chunk_size-overlap)]\n",
    "        \n",
    "        # processing base signal==================================\n",
    "        base_fftMap = computefftMap(base_signal, chosen_channels, freqs, sf)\n",
    "        base_fftMap_list.append(base_fftMap)\n",
    "        base_fd = computeFD(base_signal, chosen_channels)\n",
    "        base_fd_list.append(base_fd)\n",
    "        # ========================================================\n",
    "        \n",
    "        # [ Loop 3 ] Sliding window\n",
    "        for chunk in all_chunks:\n",
    "            # fftMap (2d array) ======================\n",
    "            fftMap = computefftMap(chunk, chosen_channels, freqs, sf)    \n",
    "            fftMap_list.append(fftMap)\n",
    "            # ========================================\n",
    "            # FD pattern (1d array)====================\n",
    "            fd = computeFD(chunk, chosen_channels)\n",
    "            fd_list.append(fd)\n",
    "            # =========================================\n",
    "            label_list.append((V,A,D,L))\n",
    "    print(\"Participant %d Ended\"%(participant_id))\n",
    "    print(time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noc = len(fftMap_list) // 1280 # num of chunks\n",
    "len(label_list) == len(fftMap_list) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_index(p_id, t_id, c_id, noc):\n",
    "    return (noc * 40) * p_id + noc * t_id + c_id\n",
    "\n",
    "def get_base_index(p_id, t_id):\n",
    "    return 40 * p_id + t_id\n",
    "\n",
    "# get p_id, t_id, c_id\n",
    "def from_data_index(index, noc):\n",
    "    # return index//40, index%40\n",
    "    p_id,remain = index // (noc*40), index % (noc*40)\n",
    "    return p_id, remain//noc, remain%noc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "save_option = \"origin\" # \"diff\"\n",
    "\n",
    "for i in range(len(fftMap_list)):\n",
    "    # activated signals (60sec)\n",
    "    if save_option == \"origin\":\n",
    "        data_list.append([fftMap_list[i], label_list[i]]) # **\n",
    "        \n",
    "    # 60sec(activate) - 3sec(base)\n",
    "    elif save_option == \"diff\":\n",
    "        p_id, t_id, c_id = from_data_index(i)\n",
    "        base_index = get_base_index(p_id, t_id)\n",
    "        \n",
    "        diff = np.array(scale(fd_list[i])) - np.array(scale(base_fd_list[base_index]))\n",
    "        data_list.append([diff, label_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DEAP_fftMap_10sec_5over.pickle', 'wb') as f:\n",
    "    pickle.dump(data_list, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SEED dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEED dataset Description\n",
    "\n",
    "* 15 Participants\n",
    "* 3 Experiment for each participant\n",
    "* 15 Trial clips for each experiment\n",
    "    * Trial clips (total 15)\n",
    "        * Sad(0) : Aftershock(2), Back to 1942(3)\n",
    "        * Neutral(1) : World Geritage in China(5)\n",
    "        * Happy(2) : Lost in Thailand(2), Flirting Scholar, Just Another Pandora's Box(2) \n",
    "    * Trial selection criteria\n",
    "        1. not too long (about 4 min)\n",
    "        2. should elicit a single desired target emotion\n",
    "        3. should be understood without explanation\n",
    "* Experiment process\n",
    "    * 5 sec base => 4 min trial => 45 sec self-assessment => 15 sec rest\n",
    "* Preprocessing\n",
    "    * downsampled to 200Hz\n",
    "    * 0 ~ 75Hz bandpass filtering\n",
    "* Total 45(=3 experiments x 15 participants) .mat files\n",
    "    * one .mat file for each experiment\n",
    "    * 16 arrays\n",
    "        * 15 arrays : preprocessed EEG data of 15 trials\n",
    "            * shape = (channel x data)\n",
    "        * 1 arrays : Labels\n",
    "            * -1 : negative\n",
    "            * 0 : neutral\n",
    "            * 1 : positive\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io # load .mat file\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "channel_path = \"EEG dataset/SEED/Channel Order.xlsx\"\n",
    "ch_file = load_workbook(channel_path, data_only=True)\n",
    "\n",
    "SEED_channels = {}\n",
    "\n",
    "for ch_idx in range(1, 63): # 1 to 62\n",
    "    SEED_channels[ch_file[\"Sheet1\"][ch_idx][0].value] = ch_idx-1\n",
    "\n",
    "SEED_all_channel_names = list(SEED_channels.keys())\n",
    "SEED_all_channel_values = list(SEED_channels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "eeg_path = \"EEG dataset/SEED/Preprocessed_EEG/\"\n",
    "\n",
    "filename_dict = defaultdict(list)\n",
    "\n",
    "for file in os.listdir(eeg_path):\n",
    "    filename_dict[int(file.split('_')[0])].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {10: ['10_20131130.mat', '10_20131204.mat', '10_20131211.mat'],\n",
       "             11: ['11_20140618.mat', '11_20140625.mat', '11_20140630.mat'],\n",
       "             12: ['12_20131127.mat', '12_20131201.mat', '12_20131207.mat'],\n",
       "             13: ['13_20140527.mat', '13_20140603.mat', '13_20140610.mat'],\n",
       "             14: ['14_20140601.mat', '14_20140615.mat', '14_20140627.mat'],\n",
       "             15: ['15_20130709.mat', '15_20131016.mat', '15_20131105.mat'],\n",
       "             1: ['1_20131027.mat', '1_20131030.mat', '1_20131107.mat'],\n",
       "             2: ['2_20140404.mat', '2_20140413.mat', '2_20140419.mat'],\n",
       "             3: ['3_20140603.mat', '3_20140611.mat', '3_20140629.mat'],\n",
       "             4: ['4_20140621.mat', '4_20140702.mat', '4_20140705.mat'],\n",
       "             5: ['5_20140411.mat', '5_20140418.mat', '5_20140506.mat'],\n",
       "             6: ['6_20130712.mat', '6_20131016.mat', '6_20131113.mat'],\n",
       "             7: ['7_20131027.mat', '7_20131030.mat', '7_20131106.mat'],\n",
       "             8: ['8_20140511.mat', '8_20140514.mat', '8_20140521.mat'],\n",
       "             9: ['9_20140620.mat', '9_20140627.mat', '9_20140704.mat']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_labels = [1, 0, -1, -1, 0, 1, -1, 0, 1, 1, 0, -1, 0, 1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization ============================\n",
    "# Label list\n",
    "label_list = [] # -1, 0, 1\n",
    "\n",
    "# Input list \n",
    "fftMap_list = [] # list of 2d-array\n",
    "base_fftMap_list = [] # base(5 sec) fft map list\n",
    "\n",
    "fd_list = []\n",
    "base_fd_list = [] \n",
    "# ===========================================\n",
    "\n",
    "# Parameters ===============================\n",
    "sf = 200\n",
    "chunk_size = 10 * sf\n",
    "overlap = 5 * sf\n",
    "\n",
    "freqs = [freq for freq in range(4,46,1)]\n",
    "\n",
    "chosen_channels = SEED_all_channel_values # SEED channels\n",
    "# chosen_channels = [0, 16, 6, 24, 11, 20, 13, 31] # [\"FP1\", \"FP2\", \"C3\", \"C4\", \"P7\", \"P8\", \"O1\", \"O2\"]\n",
    "# chosen_channels = [] # DEAP channels \n",
    "# for ch in DEAP_all_channel_names:\n",
    "#     chosen_channels.append(SEED_channels[ch])\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# index data\n",
    "ptc_to_idx = {} # key : \"participantID-trialID-chunkID\", value : index\n",
    "idx_to_ptc = [] # index => participantID-trialID-chunkID\n",
    "\n",
    "idx = 0\n",
    "\n",
    "# [ loop 1 ] : Participants\n",
    "for p_id in range(1, 16): # 1 to 15\n",
    "    experiment = io.loadmat(eeg_path + filename_dict[p_id][0])\n",
    "    \n",
    "    # [ loop 2 ] : Trials\n",
    "    t_id = 0\n",
    "    keys = list(experiment.keys())[3:] \n",
    "    for t_id in range(0, 15): \n",
    "        signal = experiment[keys[t_id]]\n",
    "        # ==============================================\n",
    "        # 2. split signal\n",
    "        base_signal = signal[:, :sf * 5] \n",
    "        total_signal = signal[:, sf * 5:] \n",
    "        \n",
    "        sig_len = total_signal.shape[1]//sf\n",
    "        \n",
    "        # all_chunks = [[start//sf, (start+chunk_size)//sf] \n",
    "        #     for start in range(0, sf*sig_len - chunk_size + 1, chunk_size-overlap)]\n",
    "        # print(\"Total %d chunks\",%(len(all_chunks))); print(all_chunks)\n",
    "        \n",
    "        all_chunks = [total_signal[:, start:start+chunk_size] \n",
    "                     for start in range(0, sf*sig_len - chunk_size + 1, chunk_size-overlap)]\n",
    "        \n",
    "        label = trial_labels[t_id]\n",
    "        # ==============================================\n",
    "        \n",
    "        # [ loop 3 ] : Chunks\n",
    "        c_id = 0\n",
    "        for chunk in all_chunks: \n",
    "            ptc_to_idx[str(p_id)+\"-\"+str(t_id)+\"-\"+str(c_id)] = idx\n",
    "            idx_to_ptc.append((p_id,t_id,c_id))\n",
    "            idx += 1; c_id += 1\n",
    "            \n",
    "            # Compute FFT Map =========================\n",
    "            fftMap = computefftMap(chunk, chosen_channels, freqs, sf)\n",
    "            fftMap_list.append(fftMap)\n",
    "            # ========================================\n",
    "            \n",
    "            # Compute FD pattern (1d array)============\n",
    "            fd = computeFD(chunk, chosen_channels)\n",
    "            fd_list.append(fd)\n",
    "            # =========================================\n",
    "            label_list.append(label)\n",
    "    print(\"Pariticipant %d Ended\"%(p_id))\n",
    "    print(time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fd_list)==len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_index(p_id, t_id, c_id):\n",
    "    return ptc_to_idx[str(p_id+1) + \"-\" + str(t_id) + \"-\" + str(c_id)]\n",
    "def get_base_index(p_id, t_id):\n",
    "    return 15 * p_id + t_id\n",
    "# get p_id, t_id, c_id\n",
    "def from_data_index(index):\n",
    "    return idx_to_ptc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "save_option = \"origin\" # \"diff\"\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    # activated signals\n",
    "    if save_option == \"origin\":\n",
    "        data_list.append([fftMap_list[i], label_list[i]])        \n",
    "    # difference between activated and base signal\n",
    "    elif save_option == \"diff\":\n",
    "        p_id, t_id, c_id = from_data_index(i, noc)\n",
    "        base_index = get_base_index(p_id, t_id)\n",
    "        \n",
    "        diff = np.array(scale(fftMap_list[i])) - np.array(scale(base_fftMap_list[base_index]))\n",
    "        data_list.append([diff, label_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SEED_fftMap_10sec_5over.pickle', 'wb') as f:\n",
    "    pickle.dump(data_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"SEED_10sec_5over_ptc_to_idx\", 'wb') as f:\n",
    "    pickle.dump(ptc_to_idx, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"SEED_10sec_5over_idx_to_ptc\", 'wb') as f:\n",
    "    pickle.dump(idx_to_ptc, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
